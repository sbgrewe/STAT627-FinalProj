```{r}
library(glmnet)
library(GGally)
library(tidyverse); theme_set(theme_bw())
reg_data_long <- read_csv(".\\..\\..\\Data\\reg_data_long.csv")
# head(reg_data_long)
reg_data_long$female_prop <- reg_data_long$FemalePop/reg_data_long$TotalPop

set.seed(123)
Z <- sample(1:nrow(reg_data_long), 0.8*nrow(reg_data_long), replace = FALSE)
train <- as.data.frame(reg_data_long[Z,])
test <- as.data.frame(reg_data_long[-Z,])
```


### Exploration of Multicollinearity


```{r}
reg_data_long[, c("Rating","CasesperThou", "prop_hpsa", "nonwhite_prop", "median_income", "unempl_prop","poverty_prop", "prop55older", "HospNumber")]

ggpairs(reg_data_long[, c("Rating","CasesperThou", "prop_hpsa", "nonwhite_prop", "median_income", "unempl_prop","poverty_prop", "prop55older", "HospNumber")])
```


There are a few potential sources of multicollinearity within the 

### Regression

The goal of this regression is to determine whether deaths per 1000 individuals due to heart disease can be predicted given demographic information, as well as information about the hospitals located within counties in California. 

In order to investigate the relationship between our predictors and the deaths due to heart disease, we employed a 10-fold LASSO regression to determine predictors with non-zero associations with the outcome, even with a shrinkage penalty. 


```{r}
model_train <- lm(DeathsperThou ~ Rating*CasesperThou + prop_hpsa + nonwhite_prop + median_income + unempl_prop 
								 + poverty_prop + Rating*prop55older + Rating*HospNumber,
								 data = train)

X_model <- model.matrix(model_train)
X_model <- X_model[,-1]
y_train <- train$DeathsperThou

model_test <- lm(DeathsperThou ~ Rating*CasesperThou + prop_hpsa + nonwhite_prop + median_income + unempl_prop 
								 + poverty_prop + Rating*prop55older + Rating*HospNumber,
								 data = test)

X_test <- model.matrix(model_test)
X_test <- X_test[,-1]
y_test <- test$DeathsperThou
```

```{r}
set.seed(123)
LASSO_reg <- cv.glmnet(X_model, y_train, alpha = 1)
cbind(coef(LASSO_reg), coef(LASSO_reg, s=LASSO_reg$lambda.min))
```

```{r}
plot(LASSO_reg)
```

```{r}
y_hat_1s <- predict(LASSO_reg, newx = X_test, type = "response", s = "lambda.1se")
y_hat_min <- predict(LASSO_reg, newx = X_test, type = "response", s = "lambda.min")

c("MSE 1se" = mean((y_hat_1s - y_test)^2), "MSE min" = mean((y_hat_min - y_test)^2))
```


The prediction MSE for the lambda 1se model with one predictors is 0.04798, while the prediction MSE for the lambda min model with seven predictors is 0.01501. The prediction error is expected to decrease by a non-negligible 68.72%. It is clear that these variables are lending predictive power to the model, but 


The results of LASSO regression reveal the relationship between hospitals of a particular quality rating and their prediction of heart disease survival. The main predictors of deaths due to heart disease appear to be the cases of heart disease and proportion of the population which is 55 years old or older. This agrees with common sense: we can imagine that the overall rate of deaths due to heart disease in a given area is due to This also provides confidence that their inclusion in the model helps to control for variation in heart disease deaths due to these direct factors.  

Interestingly, we find that the rating of a hospital has no statistically significant effect on heart attack deaths until it interacts with the number of heart attack cases. In general, subgroups of hospitals rated "Worse" tended to , while deaths due to heart disease are expected to *decrease overall* for hospitals with "Better" ratings as cases increased. In general, this means that 

We also find that there is no compelling linear association between heart disease deaths per thousand and 





