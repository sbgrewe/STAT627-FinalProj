
Here we are working on a basic multiple linear model with cross validation to investigate whether mortality rate from heart disease per 1000 people be predicted from demographic conditions within counties in California? To start, we will employ a series of multiple regressions to get a better understanding of which variables are most useful in predicting the mortality rate from heart disease. Both PercFemale and PercUnder18yo have missingness and were thus removed from the full regression model.

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse); theme_set(theme_bw())
reg_data_long <- read_csv(".\\Data\\reg_data_long.csv")
# head(reg_data_long)
reg_data_long$female_prop <- reg_data_long$FemalePop/reg_data_long$TotalPop
```

```{r}
set.seed(123)

training_pct <- .8
Z <- sample(nrow(reg_data_long), floor(training_pct*nrow(reg_data_long)))

train <- reg_data_long[Z,]
# dim(train)
test <- reg_data_long[-Z,]
# dim(test)

test$County <- factor(test$County, levels = levels(train$County))
```

### Full Model 

```{r}
full_model <- lm(DeathsperThou ~ TotalPop + MalePop + FemalePop + MedianAge + MaleMedianAge + FemaleMedianAge + Under5yoPop + Under18yoPop + Pop21andOlder + Pop55andOlder + Pop60andOlder + Pop65andOlder + num_desig + amer_indian + black + hispanic + asian + multi_race + pac_island + white + poverty + labor_force + unemployed + median_income + TotalDeaths + TotalCases + prop_hpsa + nonwhite_prop + Rating + Deaths + unempl_prop + poverty_prop + prop55older + Cases + HospNumber + CasesperThou + female_prop , data = train)
```

Looking at the full model, we see that the full model is statistically significant with a p-value of almost zero (SI). Further, it has an adjusted R^2 value of 0.9345 telling us that the model explains 93.45% of the variation in the results (@tbl-reg-MLR-summary). This is a strong result, but only a handful of the variables are significant in the model. 

When looking at plots for this model, some concerns arise. For example, the plotting on the QQ-plot does not demonstrate a strong linear relationship (SI). The edges of the plot deviate from the line suggesting that the model is not perfectly linear. Further, the scattered dots on the leverage plot show several points on the line of Cook's Distance signifying that they have overstated influence on the model.

```{r}
Yhat <- predict(full_model, newdata = test)
mse <- mean((test$DeathsperThou - Yhat)^2)
```

The prediction MSE of the full model is .0742 (@tbl-reg-MLR-summary). Next, we can see how a reduced model will work by taking only the significant variables from the above model for the reduced model. This includes variables that are significant up to the p=.1 threshold.

### Reduced Model 

```{r}
reduced_model <- lm(DeathsperThou ~ MedianAge + MaleMedianAge + FemaleMedianAge + hispanic + CasesperThou + TotalCases + HospNumber, data = train)
```

This model yields a p-value of almost zero. It has an adjusted R^2 value of 0.9104 which is lower than the previous value from the full model of 0.9345. However, the decrease in the number of variables might be worth the slightly lower R^2 value. 

```{r}
prediction_reduced <- predict(reduced_model, newdata = test)
mse_reduced <- mean((test$DeathsperThou - prediction_reduced)^2)
# mse_reduced
```
However, we see a lower MSE at  0.0539 compared to 0.0742 from the full model. However, `hispanic`, `MedianAge`, `MaleMedianAge`, `FemaleMedianAge`, and `TotalCases` are no longer significant in this model. 

To get an even better understanding of the data, we reduce the model again to just the significant variables in the reduced model. We are down to just two predictor variables, `CasesperThou` and `HospNumber`. This makes logical sense that the number of cases per thousand and the ranking of the hospital would be good predictor variables of the deaths per thousand. 

```{r}
small_model <- lm(DeathsperThou ~ CasesperThou + HospNumber, data=train)
# summary(small_model)
prediction_small <- predict(small_model, newdata = test)
mse_small <- mean((test$DeathsperThou - prediction_reduced)^2)
# mse_small
```

This small model yields the same MSE as the previous reduced model of 0.0539 and only requires two variables. We still have a p-value of almost zero. However, we continue to lose some power in the adjusted R-squared with a value of 0.9063 compared to 0.9104 in the reduced model and 0.9345 in the full model (@tbl-reg-MLR-summary). 

### Comparison Between the Two Models and Recommendation

```{r}
#| tbl-cap: "Overview of multiple linear regression models and their test performance."
#| label: tbl-reg-MLR-summary

tibble(
  Model = c("Full", "Reduced", "Smallest"),
  `Number of Predictors` = c(37, 7, 2),
  MSE = c(mse, mse_reduced, mse_small),
  `Adjusted Multiple R2` = c(0.9345, 0.9104, 0.9063)
) %>% knitr::kable(digits = 4)
```

Between the original two models, the reduced model should be chosen. It offers a more accurate prediction of the rate of deaths due to heart disease per thousand people. The reduced model uses only 7 prediction variables compared to the more than 30 variables that the full model requires. Further, the smallest model with only 2 variables gives the same low MSE value with even fewer predictor variables. This implies that many of those variables are either not useful in prediction or redundant due to multicollinearity, which we will explore. 

