```{r}
#| echo: false
#| include: false
library(tidyverse)
library(tree)
```

## Method 2: Decision Tree 

```{r}
#| echo: false
#| message: false
hpsa <- read_csv("Data/hpsa.csv")
```

```{r}
#| echo: false
set.seed(123)
Z <- sample(1:nrow(hpsa), 260)
train <- hpsa[Z,]
test <- hpsa[-Z,]
#50 score, 0.1
#20 uses designation population , error = 0.15
#70 looks good, score and population ; 0.08571
#90 ^^ ; 0.1
#140, ^^; 0.09286
#170 ^ ; 0.1353
#220 ^ 0.1273
#240 ^ ; 0.1083
#260; 0.1
#280 ^, 0.1107

#STOP AT 410 #70 percent of the observations

```

### Un-pruned decision Tree 

```{r}
#| echo: false
#| warning: false
set.seed(123)

tr <- tree(as.factor(hpsa_status) ~ ., data = train)
summary(tr)
```

```{r}
#| echo: false
plot(tr, type = "uniform")
text(tr)
```

```{r}
#| echo: false
#| warning: false
Yhat = predict(tr, newdata = test, type = "class")
```

### Pruned Tree

```{r}
#| echo: false
#| warning: false
set.seed(123)
cv <- cv.tree(tr, FUN = prune.misclass)
cv
```

```{r}
plot(cv)
```

```{r}
#which.min(cv$dev)
```

Tree size 8 corresponds to the lowest cross-validated classification error rate with the fewest nodes.

```{r}
#| echo: false
set.seed(123)
trp <- prune.misclass(tr, best = 8)
summary(trp)
```

```{r}
#| echo: false
plot(trp, type = "uniform")
text(trp)
```

## Comparing the performance of the tree model

```{r}
#| echo: false
#| warning: false
#Unpruned Tree
yhat_unpruned = predict(tr, newdata = test, type = "class")
cfmatrix_unpruned <- table(yhat_unpruned, test$hpsa_status)
test_error_rate_unpruned <- mean(yhat_unpruned != test$hpsa_status)


accuracy_unpruned <- sum(cfmatrix_unpruned[1], cfmatrix_unpruned[4])/sum(cfmatrix_unpruned)
```

```{r}
#| echo: false
#| warning: false
#Pruned Tree
yhat_pruned = predict(trp, newdata = test, type = "class")
cfmatrix_pruned <- table(yhat_pruned, test$hpsa_status)
test_error_rate_pruned <- mean(yhat_pruned != test$hpsa_status)

accuracy_pruned <- sum(cfmatrix_pruned[1], cfmatrix_pruned[4])/sum(cfmatrix_pruned)
```

```{r}
#| echo: false
library(gt)

tibble(
  models = c("Unpruned", "Pruned"),
  Accuracy = c(accuracy_unpruned, accuracy_pruned),
  Error = c(test_error_rate_unpruned, test_error_rate_pruned)
) |>
  gt() |>
  tab_header(title = "Accuracy and Prediction Error Estimates Tree models")
```

### Summary of Decision Tree models

"HPSA Score" and HPSA designation population are the dominant predictors in both the unpruned and pruned models.
The pruned tree has an mean prediction error rate of `r test_error_rate_pruned` which is a little lower than the unpruned tree which has an error rate of `r test_error_rate_unpruned`.
Meanwhile the accuracy of the pruned tree is `r accuracy_pruned` which represent a 0.3% increase in accuracy over the unpruned tree model with accuracy `r accuracy_unpruned` .
We recommend the pruned tree model.
