```{r}
#| echo: false
#| include: false
library(tidyverse)
library(tree)
```

```{r}
#| message: false
hpsa <- read_csv("Data/hpsa.csv")
```

```{r}
set.seed(123)
Z <- sample(1:nrow(hpsa), 260)
train <- hpsa[Z,]
test <- hpsa[-Z,]
#50 score, 0.1
#20 uses designation population , error = 0.15
#70 looks good, score and population ; 0.08571
#90 ^^ ; 0.1
#140, ^^; 0.09286
#170 ^ ; 0.1353
#220 ^ 0.1273
#240 ^ ; 0.1083
#260; 0.1
#280 ^, 0.1107

#STOP AT 410 #70 percent of the observations

```

## Creating an Unpruned Tree

```{r}
#| warning: false
set.seed(123)

tr <- tree(as.factor(hpsa_status) ~ ., data = train)
summary(tr)
```

```{r}
plot(tr, type = "uniform")
text(tr)
```

```{r}
#| warning: false
Yhat = predict(tr, newdata = test, type = "class")
table(Yhat, test$hpsa_status)
mean(Yhat != test$hpsa_status) #test error rate
```

## Creating a Pruned Tree

Uses cv.tree on the training set to determine the optimal tree size based on the misclassification rate

```{r}
#| warning: false
set.seed(123)
cv <- cv.tree(tr, FUN = prune.misclass)
cv
```

```{r}
plot(cv)
```

```{r}
which.min(cv$dev)
```

Tree size 8 corresponds to the lowest cross-validated classification error rate with the fewest nodes.

```{r}
set.seed(123)
trp <- prune.misclass(tr, best = 8)
summary(trp)
```

"HPSA Score" and HPSA designation population remains in this node, but with reduced nodes.

```{r}
plot(trp, type = "uniform")
text(trp)
```

## Comparing the Error Rates of the Trees

```{r}
#| warning: false
#Unpruned Tree
yhat_unpruned = predict(tr, newdata = test, type = "class")
cfmatrix_unpruned <- table(yhat_unpruned, test$hpsa_status)
test_error_rate_unpruned <- mean(yhat_unpruned != test$hpsa_status)


accuracy_unpruned <- sum(cfmatrix_unpruned[1], cfmatrix_unpruned[4])/sum(cfmatrix_unpruned)

accuracy_unpruned
test_error_rate_unpruned
```

```{r}
#| warning: false
#Pruned Tree
yhat_pruned = predict(trp, newdata = test, type = "class")
cfmatrix_pruned <- table(yhat_pruned, test$hpsa_status)
test_error_rate_pruned <- mean(yhat_pruned != test$hpsa_status)

accuracy_pruned <- sum(cfmatrix_pruned[1], cfmatrix_pruned[4])/sum(cfmatrix_pruned)

accuracy_pruned
test_error_rate_pruned
```

The test error rates are not equal.
The pruned tree has an error rate of `r test_error_rate_pruned` which is a little lower than the unpruned tree which has an error rate of `r test_error_rate_unpruned`.
Meanwhile the accuracy of the pruned tree is `r accuracy_pruned` which is higher than that of the unpruned tree `r accuracy_unpruned` .
We recommend the pruned tree more.

```{r}
library(gt)

tibble(
  models = c("Unpruned", "Pruned"),
  Accuracy = c(accuracy_unpruned, accuracy_pruned),
  Error = c(test_error_rate_unpruned, test_error_rate_pruned)
) |>
  gt() |>
  tab_header(title = "Accuracy and Prediction Error Estimates Tree models")
```

\
